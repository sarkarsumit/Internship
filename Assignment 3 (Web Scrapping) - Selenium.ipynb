{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write a python program which searches all the product under a particular product from www.amazon.in. The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium #Library that is used to work with selenium\n",
    "import pandas as pd #to create dataframe\n",
    "from selenium import webdriver #importing webdriver module from selenium to open up automated chrome window\n",
    "import warnings #to ignore any sort of warning\n",
    "warnings.filterwarnings('ignore')\n",
    "import time #use to stop serach engine for few seconds\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"C:/Web Driver/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product you want to search:guitar\n"
     ]
    }
   ],
   "source": [
    "url=\"https://www.amazon.in\"\n",
    "driver.get(url)\n",
    "user_inp=input(\"Enter the product you want to search:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_bar=driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search_bar.clear()\n",
    "search_bar.send_keys(user_inp)\n",
    "time.sleep(3)\n",
    "search_btn=driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then scrape all the products available under that product name. Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and “Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Name of the Product</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "      <th>Return/Exchange</th>\n",
       "      <th>Expected Delivery</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Product URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Medellin</td>\n",
       "      <td>Medellin carbn fiber guitar 38inch (BROWN)</td>\n",
       "      <td>3.6 out of 5</td>\n",
       "      <td>₹2,499</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>-</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>https://www.amazon.in/gp/slredirect/picassoRed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kadence</td>\n",
       "      <td>Kadence Frontier guitar with Online Guitar lea...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>-</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>Thursday, May 26</td>\n",
       "      <td></td>\n",
       "      <td>https://www.amazon.in/gp/slredirect/picassoRed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kadence</td>\n",
       "      <td>Kadence Frontier Jumbo Semi Acoustic Guitar Wi...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>-</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>-</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>https://www.amazon.in/gp/slredirect/picassoRed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VAULT</td>\n",
       "      <td>Vault Traveller 34 Inch Acoustic Guitar With B...</td>\n",
       "      <td>3.9 out of 5</td>\n",
       "      <td>₹3,999</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>-</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>https://www.amazon.in/gp/slredirect/picassoRed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intern</td>\n",
       "      <td>Intern INT-38C Acoustic Guitar Kit, With Bag, ...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>₹3,274</td>\n",
       "      <td>7 Days Replacement</td>\n",
       "      <td>-</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>https://www.amazon.in/Intern-INT-38C-Acoustic-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand                                Name of the Product        Rating  \\\n",
       "0  Medellin         Medellin carbn fiber guitar 38inch (BROWN)  3.6 out of 5   \n",
       "1  Kadence   Kadence Frontier guitar with Online Guitar lea...    4 out of 5   \n",
       "2  Kadence   Kadence Frontier Jumbo Semi Acoustic Guitar Wi...    4 out of 5   \n",
       "3    VAULT   Vault Traveller 34 Inch Acoustic Guitar With B...  3.9 out of 5   \n",
       "4   Intern   Intern INT-38C Acoustic Guitar Kit, With Bag, ...    4 out of 5   \n",
       "\n",
       "    Price     Return/Exchange Expected Delivery Availability  \\\n",
       "0  ₹2,499  7 Days Replacement                 -    In stock.   \n",
       "1       -  7 Days Replacement  Thursday, May 26                \n",
       "2       -  7 Days Replacement                 -    In stock.   \n",
       "3  ₹3,999  7 Days Replacement                 -    In stock.   \n",
       "4  ₹3,274  7 Days Replacement                 -    In stock.   \n",
       "\n",
       "                                         Product URL  \n",
       "0  https://www.amazon.in/gp/slredirect/picassoRed...  \n",
       "1  https://www.amazon.in/gp/slredirect/picassoRed...  \n",
       "2  https://www.amazon.in/gp/slredirect/picassoRed...  \n",
       "3  https://www.amazon.in/gp/slredirect/picassoRed...  \n",
       "4  https://www.amazon.in/Intern-INT-38C-Acoustic-...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_url = [] #creating empty list file to collect each product URL\n",
    "\n",
    "# using for loop collecting all 3 pages all product Url\n",
    "for i in range(0,2):  # next 2 pages moved by this loop\n",
    "    time.sleep(2)\n",
    "  \n",
    "    for j in driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-no-outline']\"):\n",
    "        product_url.append(j.get_attribute(\"href\"))\n",
    "    \n",
    "# creating the empty list to scrap the data\n",
    "brand_name = []\n",
    "product_name = []\n",
    "rating = []\n",
    "num_rating = []\n",
    "price = []\n",
    "return_exchange = []\n",
    "exp_delivery = []\n",
    "avilablity = []\n",
    "other_detail = []\n",
    "\n",
    "# Scraping the all detail of each product\n",
    "for i in product_url:\n",
    "    driver.get(i)\n",
    "    # Scraping product name\n",
    "    try:\n",
    "        product = driver.find_element_by_id(\"productTitle\")\n",
    "        product_name.append(product.text)\n",
    "    except NoSuchElementException:\n",
    "        product_name.append(\"-\")\n",
    "         \n",
    "    #Scraping brand name\n",
    "    try:\n",
    "        brand= driver.find_element_by_id(\"bylineInfo\")\n",
    "        spl=brand.text.replace(\"Visit the \",\"\")\n",
    "        spl=spl.replace(\"Store\",\"\")\n",
    "        spl=spl.replace(\"Brand: \",\"\")\n",
    "        brand_name.append(spl)\n",
    "    except NoSuchElementException:\n",
    "        brand_name.append(\"-\")\n",
    "  \n",
    "    \n",
    "    #Scraping rating\n",
    "    try:\n",
    "        rate = driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']//span\")\n",
    "        rating.append(rate.text)\n",
    "    except NoSuchElementException:\n",
    "        rating.append(\"-\")\n",
    "    \n",
    "    #Scraping price of the product\n",
    "    try:\n",
    "        pri = driver.find_element_by_xpath(\"//span[@class='a-price aok-align-center']\")\n",
    "        price.append(pri.text.replace(\"\\n00\",\"\"))\n",
    "    except NoSuchElementException:\n",
    "        price.append(\"-\")\n",
    "     #Scraping return/exchange of the product    \n",
    "    try:\n",
    "        return_pol =driver.find_element_by_xpath(\"//span[@class='a-declarative']//div[2]//a\")\n",
    "        return_exchange.append(return_pol.text)\n",
    "    except NoSuchElementException:\n",
    "        return_exchange.append(\"-\")\n",
    "    #Scraping delivery of the product            \n",
    "    try:            \n",
    "        exp_del = driver.find_element_by_xpath(\"//div[@id='ddmDeliveryMessage']//b\")\n",
    "        exp_delivery.append(exp_del.text)\n",
    "    except NoSuchElementException:\n",
    "         exp_delivery.append(\"-\") \n",
    "            \n",
    "    #Scraping availability of the product \n",
    "    try:\n",
    "        avil = driver.find_element_by_xpath(\"//div[@id='availability']//span\")\n",
    "        avilablity.append(avil.text)\n",
    "    except NoSuchElementException:\n",
    "        avilablity.append(\"-\")\n",
    "   \n",
    "                 \n",
    "    time.sleep(1)\n",
    "\n",
    "# Creating Dataframe \n",
    "df = pd.DataFrame()\n",
    "df[\"Brand\"] = brand_name\n",
    "df[\"Name of the Product\"] = product_name\n",
    "df[\"Rating\"] = rating\n",
    "df[\"Price\"] = price\n",
    "df[\"Return/Exchange\"] = return_exchange\n",
    "df[\"Expected Delivery\"] = exp_delivery\n",
    "df[\"Availability\"] = avilablity\n",
    "df[\"Product URL\"] = product_url \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write a python program to access the search bar and search button on images.google.com and scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Machine Learning</th>\n",
       "      <th>Guitar</th>\n",
       "      <th>Cakes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "      <td>data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Fruits  \\\n",
       "0  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "1  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "2  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "3  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "4  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "5  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "6  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "7  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "8  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "9  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "\n",
       "                                                Cars  \\\n",
       "0  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "1  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "2  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "3  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "4  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "5  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "6  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "7  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "8  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "9  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "\n",
       "                                    Machine Learning  \\\n",
       "0  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "1  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "2  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "3  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "4  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "5  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "6  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "7  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "8  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "9  data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAA...   \n",
       "\n",
       "                                              Guitar  \\\n",
       "0  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "1  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "2  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "3  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "4  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "5  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "6  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "7  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "8  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "9  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   \n",
       "\n",
       "                                               Cakes  \n",
       "0  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...  \n",
       "1  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...  \n",
       "2  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...  \n",
       "3  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...  \n",
       "4  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...  \n",
       "5  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...  \n",
       "6  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...  \n",
       "7  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...  \n",
       "8  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...  \n",
       "9  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drive = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# empty list creating to scrap the detail\n",
    "fruit_image = []\n",
    "car_image = []\n",
    "machineLearning_image = []\n",
    "guitar_image = []\n",
    "cakes_image = []\n",
    "\n",
    "\n",
    "# iterating 3 types of image\n",
    "for i in ['fruits','cars','machine learning','Guitar','cakes']:\n",
    "    # opening google img website\n",
    "    url = \"https://images.google.com/?gws_rd=ssl\"\n",
    "    driver.get(url)\n",
    "    time.sleep(4)\n",
    "    \n",
    "    \n",
    "    #Scraping the fruits detail\n",
    "    if i == 'fruits':\n",
    "        # Accessing search bar and search button\n",
    "        search_bar = driver.find_element_by_xpath(\"//input[@class='gLFyf gsfi']\").send_keys(i)\n",
    "        search_btn=driver.find_element_by_xpath(\"//span[@class= 'z1asCe MZy1Rb']\")\n",
    "        driver.execute_script('arguments[0].click()', search_btn)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # first 10 image of fruit scraping\n",
    "        for i in range(0,3):\n",
    "            for i in driver.find_elements_by_xpath(\"//img[@class='rg_i Q4LuWd']\"):\n",
    "                if len(fruit_image) < 10:\n",
    "                    fruit_image.append(i.get_attribute(\"src\"))\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    break\n",
    "            driver.execute_script(\"window.scrollTo(0, 1000)\")#scroll down the website\n",
    "            time.sleep(4)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #Scraping the cars detail    \n",
    "    elif i == 'cars':\n",
    "        # Accessing search bar and search button\n",
    "        search_bar = driver.find_element_by_xpath(\"//input[@class='gLFyf gsfi']\").send_keys(i)\n",
    "        time.sleep(2)\n",
    "        search_btn=driver.find_element_by_xpath(\"//span[@class= 'z1asCe MZy1Rb']\")\n",
    "        driver.execute_script('arguments[0].click()', search_btn)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # first 10 image of car scraping\n",
    "        for i in range(0,3):\n",
    "            for i in driver.find_elements_by_xpath(\"//img[@class='rg_i Q4LuWd']\"):\n",
    "                if len(car_image) < 10:\n",
    "                    car_image.append(i.get_attribute(\"src\"))\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    break\n",
    "            driver.execute_script(\"window.scrollTo(0, 1000)\") #scroll down the website\n",
    "            time.sleep(4)\n",
    "        \n",
    "    #Scraping the machine learning detail     \n",
    "    elif i == 'machine learning':\n",
    "        # Accessing search bar and search button\n",
    "        search_bar = driver.find_element_by_xpath(\"//input[@class='gLFyf gsfi']\").send_keys(i)\n",
    "        time.sleep(2)\n",
    "        search_btn=driver.find_element_by_xpath(\"//span[@class= 'z1asCe MZy1Rb']\")\n",
    "        driver.execute_script('arguments[0].click()', search_btn)        \n",
    "        time.sleep(2)\n",
    "        \n",
    "        # first 10 image of machinelearning scraping        \n",
    "        for i in range(0,3):\n",
    "            for i in driver.find_elements_by_xpath(\"//img[@class='rg_i Q4LuWd']\"):\n",
    "                if len(machineLearning_image) < 10:\n",
    "                    machineLearning_image.append(i.get_attribute(\"src\"))\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    break\n",
    "            driver.execute_script(\"window.scrollTo(0, 1000)\")#scroll down the website\n",
    "            time.sleep(4) \n",
    "\n",
    "   #Scraping the guitar detail\n",
    "    if i == 'Guitar':\n",
    "        # Accessing search bar and search button\n",
    "        search_bar = driver.find_element_by_xpath(\"//input[@class='gLFyf gsfi']\").send_keys(i)\n",
    "        time.sleep(2)\n",
    "        search_btn=driver.find_element_by_xpath(\"//span[@class= 'z1asCe MZy1Rb']\")\n",
    "        driver.execute_script('arguments[0].click()', search_btn)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # first 10 image of fruit scraping\n",
    "        for i in range(0,3):\n",
    "            for i in driver.find_elements_by_xpath(\"//img[@class='rg_i Q4LuWd']\"):\n",
    "                if len(guitar_image) < 10:\n",
    "                    guitar_image.append(i.get_attribute(\"src\"))\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    break\n",
    "            driver.execute_script(\"window.scrollTo(0, 1000)\")#scroll down the website\n",
    "            time.sleep(4)\n",
    "        \n",
    "   #Scraping the cakes detail\n",
    "    if i == 'cakes':\n",
    "        # Accessing search bar and search button\n",
    "        search_bar = driver.find_element_by_xpath(\"//input[@class='gLFyf gsfi']\").send_keys(i)\n",
    "        time.sleep(2)\n",
    "        search_btn=driver.find_element_by_xpath(\"//span[@class= 'z1asCe MZy1Rb']\")\n",
    "        driver.execute_script('arguments[0].click()', search_btn)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # first 10 image of fruit scraping\n",
    "        for i in range(0,3):\n",
    "            for i in driver.find_elements_by_xpath(\"//img[@class='rg_i Q4LuWd']\"):\n",
    "                if len(cakes_image) < 10:\n",
    "                    cakes_image.append(i.get_attribute(\"src\"))\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    break\n",
    "            driver.execute_script(\"window.scrollTo(0, 1000)\")#scroll down the website\n",
    "            time.sleep(4)\n",
    "                            \n",
    "            \n",
    "            \n",
    "#creating dataframe            \n",
    "google = pd.DataFrame()\n",
    "google['Fruits'] = fruit_image  \n",
    "google['Cars'] = car_image\n",
    "google['Machine Learning'] = machineLearning_image\n",
    "google['Guitar'] = guitar_image\n",
    "google['Cakes'] = cakes_image\n",
    "\n",
    "google"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the product :smartphone\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Smart Phone Name</th>\n",
       "      <th>Color</th>\n",
       "      <th>Ram</th>\n",
       "      <th>Stroage(ROM)</th>\n",
       "      <th>Primary Camera</th>\n",
       "      <th>Secondary Camera</th>\n",
       "      <th>Display Size</th>\n",
       "      <th>Battery Capacity</th>\n",
       "      <th>Price</th>\n",
       "      <th>Product link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POCO</td>\n",
       "      <td>POCO C31</td>\n",
       "      <td>Royal Blue</td>\n",
       "      <td>4 GB RAM</td>\n",
       "      <td>64 GB ROM</td>\n",
       "      <td>13MP + 2MP + 2MP</td>\n",
       "      <td>5MP Front Camera</td>\n",
       "      <td>16.59 cm (6.53 inch) HD+ Display</td>\n",
       "      <td>[5000, mAh]</td>\n",
       "      <td>₹9,499</td>\n",
       "      <td>https://www.flipkart.com/poco-c31-royal-blue-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MOTOROLA</td>\n",
       "      <td>MOTOROLA G60</td>\n",
       "      <td>Moonless</td>\n",
       "      <td>6 GB RAM</td>\n",
       "      <td>128 GB ROM</td>\n",
       "      <td>108MP + 8MP + 2MP</td>\n",
       "      <td>32MP Front Camera</td>\n",
       "      <td>17.22 cm (6.78 inch) Full HD+ Display</td>\n",
       "      <td>[6000, mAh]</td>\n",
       "      <td>₹15,999</td>\n",
       "      <td>https://www.flipkart.com/motorola-g60-moonless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>realme</td>\n",
       "      <td>realme C11 2021</td>\n",
       "      <td>Cool Grey</td>\n",
       "      <td>2 GB RAM</td>\n",
       "      <td>32 GB ROM</td>\n",
       "      <td>8MP Rear Camera</td>\n",
       "      <td>5MP Front Camera</td>\n",
       "      <td>16.51 cm (6.5 inch) HD+ Display</td>\n",
       "      <td>[5000, mAh]</td>\n",
       "      <td>₹7,499</td>\n",
       "      <td>https://www.flipkart.com/realme-c11-2021-cool-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>I Kall Z5</td>\n",
       "      <td>Pink</td>\n",
       "      <td>3 GB RAM</td>\n",
       "      <td>16 GB ROM</td>\n",
       "      <td>8MP Rear Camera</td>\n",
       "      <td>5MP Front Camera</td>\n",
       "      <td>13.84 cm (5.45 inch) Display</td>\n",
       "      <td>[3000, mAh]</td>\n",
       "      <td>₹4,799</td>\n",
       "      <td>https://www.flipkart.com/kall-z5-pink-16-gb/p/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realme</td>\n",
       "      <td>realme C11 2021</td>\n",
       "      <td>Cool Blue</td>\n",
       "      <td>2 GB RAM</td>\n",
       "      <td>32 GB ROM</td>\n",
       "      <td>8MP Rear Camera</td>\n",
       "      <td>5MP Front Camera</td>\n",
       "      <td>16.51 cm (6.5 inch) HD+ Display</td>\n",
       "      <td>[5000, mAh]</td>\n",
       "      <td>₹7,499</td>\n",
       "      <td>https://www.flipkart.com/realme-c11-2021-cool-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand  Smart Phone Name       Color        Ram Stroage(ROM)  \\\n",
       "0      POCO         POCO C31   Royal Blue  4 GB RAM    64 GB ROM    \n",
       "1  MOTOROLA     MOTOROLA G60     Moonless  6 GB RAM    128 GB ROM   \n",
       "2    realme  realme C11 2021    Cool Grey  2 GB RAM    32 GB ROM    \n",
       "3         I        I Kall Z5         Pink  3 GB RAM     16 GB ROM   \n",
       "4    realme  realme C11 2021    Cool Blue  2 GB RAM    32 GB ROM    \n",
       "\n",
       "       Primary Camera    Secondary Camera  \\\n",
       "0   13MP + 2MP + 2MP     5MP Front Camera   \n",
       "1  108MP + 8MP + 2MP    32MP Front Camera   \n",
       "2    8MP Rear Camera     5MP Front Camera   \n",
       "3    8MP Rear Camera     5MP Front Camera   \n",
       "4    8MP Rear Camera     5MP Front Camera   \n",
       "\n",
       "                            Display Size Battery Capacity    Price  \\\n",
       "0       16.59 cm (6.53 inch) HD+ Display      [5000, mAh]   ₹9,499   \n",
       "1  17.22 cm (6.78 inch) Full HD+ Display      [6000, mAh]  ₹15,999   \n",
       "2        16.51 cm (6.5 inch) HD+ Display      [5000, mAh]   ₹7,499   \n",
       "3           13.84 cm (5.45 inch) Display      [3000, mAh]   ₹4,799   \n",
       "4        16.51 cm (6.5 inch) HD+ Display      [5000, mAh]   ₹7,499   \n",
       "\n",
       "                                        Product link  \n",
       "0  https://www.flipkart.com/poco-c31-royal-blue-6...  \n",
       "1  https://www.flipkart.com/motorola-g60-moonless...  \n",
       "2  https://www.flipkart.com/realme-c11-2021-cool-...  \n",
       "3  https://www.flipkart.com/kall-z5-pink-16-gb/p/...  \n",
       "4  https://www.flipkart.com/realme-c11-2021-cool-...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Accessing link of flipkart to search smart phone \n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#Seaching mobile\n",
    "search_bar = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']//input\")\n",
    "#User input\n",
    "text = input(\"Enter the product :\")\n",
    "search_bar.send_keys(text)\n",
    "time.sleep(2)\n",
    "#Searching the product\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "driver.execute_script('arguments[0].click()', search_btn)\n",
    "time.sleep(3)\n",
    "\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "\n",
    "#details need to scrap\n",
    "brand_name = []\n",
    "smart_phone_name = []\n",
    "color = []\n",
    "ram = []\n",
    "storage = []\n",
    "pri_cam = []\n",
    "sec_cam =[]\n",
    "bat_capacity = []\n",
    "price = []\n",
    "product_url =[]\n",
    "dis_size = []\n",
    "dis_res = []\n",
    "\n",
    "\n",
    "#scraping\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='_4rR01T']\")[:24]:\n",
    "        brand_name.append(i.text.split(\" \")[0])\n",
    "        smart_phone_name.append(i.text.split(\"(\")[0])\n",
    "        color.append(i.text.split(\"(\")[1].split(\",\")[0])\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class='_1xgFaf']//li[1]\")[:24]:\n",
    "    ram.append(i.text.split(\"|\")[0])\n",
    "    storage.append(i.text.split(\"|\")[1])   \n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class='_1xgFaf']//li[3]\")[:24]:\n",
    "    pri_cam.append(i.text.split(\"|\")[0])\n",
    "    try:\n",
    "        sec_cam.append(i.text.split(\"|\")[1])\n",
    "    except:\n",
    "        sec_cam.append(\"-\")\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//ul[@class='_1xgFaf']//li[4]\")[:24]:\n",
    "    bat_capacity.append(i.text.split(\" \")[:2])\n",
    "\n",
    "\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='_30jeq3 _1_WHN1']\")[:24]:\n",
    "    price.append(i.text)\n",
    "    \n",
    "time.sleep(2)  \n",
    "# scraping all product url \n",
    "for i in driver.find_elements_by_xpath(\"//a[@class='_1fQZEK']\")[:24]:\n",
    "    product_url.append(i.get_attribute(\"href\"))\n",
    "    time.sleep(3) \n",
    "    \n",
    "# display resolution and size scraping \n",
    "for i in product_url:\n",
    "    driver.get(i)\n",
    "        \n",
    "    # handling the exception\n",
    "    try:\n",
    "        driver.execute_script(\"window.scrollTo(0, 2000)\")\n",
    "        driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _1FH0tX']\").click()\n",
    "        time.sleep(4)\n",
    "    except ElementClickInterceptedException:\n",
    "        pass\n",
    "        time.sleep(2)\n",
    "    try:\n",
    "        driver.execute_script(\"window.scrollTo(0, 2100)\")\n",
    "        time.sleep(4)\n",
    "        d_siz = driver.find_element_by_xpath(\"//li[2][@class='_21Ahn-']\")\n",
    "        dis_size.append(d_siz.text)\n",
    "    except:\n",
    "        dis_size.append(\"-\")\n",
    "\n",
    "            \n",
    "# scraping all product url            \n",
    "for i in product_url:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        driver.execute_script(\"window.scrollTo(0, 2100)\")\n",
    "        driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _1FH0tX']\").click()\n",
    "        time.sleep(4)\n",
    "    except ElementClickInterceptedException:\n",
    "        pass\n",
    "    \n",
    "      \n",
    "\n",
    "#Creating dataframe and CSV file\n",
    "SmartPhone = pd.DataFrame()\n",
    "SmartPhone['Brand'] = brand_name\n",
    "SmartPhone['Smart Phone Name']= smart_phone_name\n",
    "SmartPhone['Color']=color\n",
    "SmartPhone['Ram']= ram\n",
    "SmartPhone ['Stroage(ROM)'] = storage \n",
    "SmartPhone ['Primary Camera'] = pri_cam\n",
    "SmartPhone ['Secondary Camera'] = sec_cam\n",
    "SmartPhone ['Display Size']=dis_size\n",
    "SmartPhone ['Battery Capacity'] = bat_capacity\n",
    "SmartPhone ['Price'] = price\n",
    "SmartPhone ['Product link'] = product_url\n",
    "\n",
    "SmartPhone.to_csv(\"SmartPhone.csv\")\n",
    "SmartPhone.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the city Name : Chennai\n",
      "Enter the city Name : Mumbai\n",
      "Enter the city Name : Kolkata\n",
      "Enter the city Name : Delhi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Url</th>\n",
       "      <th>lattitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chennai</td>\n",
       "      <td>https://www.google.co.in/maps/place/Chennai,+T...</td>\n",
       "      <td>13.0473747</td>\n",
       "      <td>79.9287943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>https://www.google.co.in/maps/place/Mumbai,+Ma...</td>\n",
       "      <td>19.082039</td>\n",
       "      <td>72.6009708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kolkata</td>\n",
       "      <td>https://www.google.co.in/maps/place/Kolkata,+W...</td>\n",
       "      <td>22.6750204</td>\n",
       "      <td>87.7691741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>https://www.google.co.in/maps/place/Delhi/@28....</td>\n",
       "      <td>28.6466772</td>\n",
       "      <td>76.813053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      City                                                Url   lattitude  \\\n",
       "0  Chennai  https://www.google.co.in/maps/place/Chennai,+T...  13.0473747   \n",
       "1   Mumbai  https://www.google.co.in/maps/place/Mumbai,+Ma...   19.082039   \n",
       "2  Kolkata  https://www.google.co.in/maps/place/Kolkata,+W...  22.6750204   \n",
       "3    Delhi  https://www.google.co.in/maps/place/Delhi/@28....  28.6466772   \n",
       "\n",
       "    longitude  \n",
       "0  79.9287943  \n",
       "1  72.6009708  \n",
       "2  87.7691741  \n",
       "3   76.813053  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re #importing regular expression module to scrap the data\n",
    "\n",
    "\n",
    "# opening web chrome browser\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "# writing url to search city\n",
    "driver.get(\"https://www.google.co.in/maps\")\n",
    "time.sleep(3)\n",
    "\n",
    "city_list = []\n",
    "url =[]\n",
    "lattitude=[]\n",
    "longitude =[]\n",
    "\n",
    "\n",
    "for i in range(0,4):\n",
    "    city = input('Enter the city Name : ')                                 # Enter city to be searched\n",
    "    city_list.append(city) \n",
    "    \n",
    "    search = driver.find_element_by_id(\"searchboxinput\")                   # locating search bar\n",
    "    search.clear()                                                         # clearing search bar\n",
    "    time.sleep(2)\n",
    "    search.send_keys(city)                                                 # entering values in search bar\n",
    "    button = driver.find_element_by_id(\"searchbox-searchbutton\")           # locating search button\n",
    "    button.click()                                                         # clicking search button\n",
    "    time.sleep(3)\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "        url_string = driver.current_url # current Url of the city is extracted\n",
    "        url.append(url_string)\n",
    "    \n",
    "        lat_lng = re.findall(r'@(.*)data',url_string)\n",
    "\n",
    "        if len(lat_lng):\n",
    "\n",
    "            lat_lng_list = lat_lng[0].split(\",\")\n",
    "\n",
    "            if len(lat_lng_list)>=2:\n",
    "\n",
    "                lat = lat_lng_list[0]\n",
    "\n",
    "                lng = lat_lng_list[1]\n",
    "            \n",
    "                lattitude.append(lat)\n",
    "                longitude.append(lng)\n",
    "    except Exception as e:\n",
    "\n",
    "        print(\"Error: \", str(e))\n",
    "        \n",
    "\n",
    "# Creating dataframe\n",
    "Geo_coordinates = pd.DataFrame()\n",
    "Geo_coordinates['City'] = city_list \n",
    "Geo_coordinates['Url'] = url\n",
    "Geo_coordinates['lattitude']= lattitude\n",
    "Geo_coordinates['longitude'] =longitude\n",
    "\n",
    "Geo_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Write a program to scrap details of all the funding deals for second quarter (i.e Jan 21 – March 21) from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Startup Name</th>\n",
       "      <th>Industry/Vertical</th>\n",
       "      <th>Sub-Vertical</th>\n",
       "      <th>Location</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Investment Type</th>\n",
       "      <th>Amount(in USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/01/2021</td>\n",
       "      <td>Digit Insurance</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Insurance Services</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>A91 Partners, Faering Capital, TVS Capital Funds</td>\n",
       "      <td>Venture</td>\n",
       "      <td>1,80,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28/01/2021</td>\n",
       "      <td>Bombay Shaving Company</td>\n",
       "      <td>Consumer Goods Company</td>\n",
       "      <td>Shave care, beard care, and skincare products</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Reckitt Benckiser</td>\n",
       "      <td>Venture</td>\n",
       "      <td>6,172,258.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19/01/2021</td>\n",
       "      <td>DeHaat</td>\n",
       "      <td>AgriTech Startup</td>\n",
       "      <td>online marketplace for farm products and services</td>\n",
       "      <td>Patna</td>\n",
       "      <td>Prosus Ventures</td>\n",
       "      <td>Series C</td>\n",
       "      <td>30,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19/01/2021</td>\n",
       "      <td>Darwinbox</td>\n",
       "      <td>SaaS</td>\n",
       "      <td>HR Tech</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Salesforce Ventures</td>\n",
       "      <td>Seed</td>\n",
       "      <td>15,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18/01/2021</td>\n",
       "      <td>mfine</td>\n",
       "      <td>Health Tech Startup</td>\n",
       "      <td>AI-powered telemedicine mobile app</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Heritas Capital Management</td>\n",
       "      <td>Venture Round</td>\n",
       "      <td>16,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18/01/2021</td>\n",
       "      <td>Udayy</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>Online learning platform for kids in class 1-5</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Sequoia Capital</td>\n",
       "      <td>Seed Funding</td>\n",
       "      <td>15,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11/01/2021</td>\n",
       "      <td>True Elements</td>\n",
       "      <td>Food Startup</td>\n",
       "      <td>Whole Food plant based Nashta</td>\n",
       "      <td>Pune</td>\n",
       "      <td>SIDBI Venture Capital</td>\n",
       "      <td>Series</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13/01/2021</td>\n",
       "      <td>Saveo</td>\n",
       "      <td>B2B E-commerce</td>\n",
       "      <td>Pharmacies</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Matrix Partners India, RTP Global, others</td>\n",
       "      <td>Seed</td>\n",
       "      <td>4,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11/02/2021</td>\n",
       "      <td>Doubtnut</td>\n",
       "      <td>Edu Tech</td>\n",
       "      <td>E-Learning Platform</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>SIG Global, Sequoia Capital, WaterBridge Ventu...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>2,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22/02/2021</td>\n",
       "      <td>Zomato</td>\n",
       "      <td>Hospitality</td>\n",
       "      <td>Online Food Delivery Platform</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Tiger Global, Kora</td>\n",
       "      <td>Venture</td>\n",
       "      <td>250,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19/02/2021</td>\n",
       "      <td>Fingerlix</td>\n",
       "      <td>Hospitality</td>\n",
       "      <td>Semi-cooked food delivery app</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Rhodium Trust, Accel Partners and Swiggy</td>\n",
       "      <td>Series C</td>\n",
       "      <td>2,747,045.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17/02/2021</td>\n",
       "      <td>Zolve</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Global Neobank Venture</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Accel Partners and Lightspeed Venture Partners</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1,50,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15/02/2021</td>\n",
       "      <td>KreditBee</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Digital lending platform</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Azim Premji’s PremjiInvest and South Korea’s M...</td>\n",
       "      <td>Series C</td>\n",
       "      <td>75,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12/02/2021</td>\n",
       "      <td>Pepperfry</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Multi-brand furniture brand</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>InnoVen Capital</td>\n",
       "      <td>Debt Financing</td>\n",
       "      <td>4,773,958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12/02/2021</td>\n",
       "      <td>Grofers</td>\n",
       "      <td>E-Commerce</td>\n",
       "      <td>Online supermarket</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>SoftBank Vision Fund (SVF)</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>55,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>09/02/2021</td>\n",
       "      <td>Nothing</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Consumer Technology Venture</td>\n",
       "      <td>London</td>\n",
       "      <td>GV</td>\n",
       "      <td>Series A</td>\n",
       "      <td>15,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>09/02/2021</td>\n",
       "      <td>SplashLearn</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>Game-based learning programme</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Owl Ventures</td>\n",
       "      <td>Series C</td>\n",
       "      <td>18,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>04/03/2021</td>\n",
       "      <td>DealShare</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online shopping platform</td>\n",
       "      <td>Jaipur, Rajasthan</td>\n",
       "      <td>Innoven Capital</td>\n",
       "      <td>Debt Financing</td>\n",
       "      <td>250,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31/03/2021</td>\n",
       "      <td>Uniphore</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Conversational Service Automation (CSA)</td>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Sorenson Capital Partners</td>\n",
       "      <td>Series D</td>\n",
       "      <td>140,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30/03/2021</td>\n",
       "      <td>Dunzo</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Hyper-local delivery app</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Krishtal Advisors Pte Ltd</td>\n",
       "      <td>Series E</td>\n",
       "      <td>8,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30/03/2021</td>\n",
       "      <td>BYJU’S</td>\n",
       "      <td>Edu-tech</td>\n",
       "      <td>Online tutoring</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>MC Global Edtech, B Capital, Baron, others</td>\n",
       "      <td>Series F</td>\n",
       "      <td>460,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23/03/2021</td>\n",
       "      <td>SkilloVilla</td>\n",
       "      <td>Edu-tech</td>\n",
       "      <td>Career and job-oriented upskilling.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Titan Capital, others</td>\n",
       "      <td>Seed</td>\n",
       "      <td>300,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25/03/2021</td>\n",
       "      <td>CityMall</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Social ecommerce and online grocery platform</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Accel Partners</td>\n",
       "      <td>Series A</td>\n",
       "      <td>11,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>26/03/2021</td>\n",
       "      <td>DotPe</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Commerce and payments platform to offline ente...</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>PayU</td>\n",
       "      <td>Series A</td>\n",
       "      <td>27,500,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date            Startup Name       Industry/Vertical  \\\n",
       "0   15/01/2021         Digit Insurance      Financial Services   \n",
       "1   28/01/2021  Bombay Shaving Company  Consumer Goods Company   \n",
       "2   19/01/2021                  DeHaat        AgriTech Startup   \n",
       "3   19/01/2021               Darwinbox                    SaaS   \n",
       "4   18/01/2021                   mfine     Health Tech Startup   \n",
       "5   18/01/2021                   Udayy                  EdTech   \n",
       "6   11/01/2021           True Elements            Food Startup   \n",
       "7   13/01/2021                   Saveo          B2B E-commerce   \n",
       "8   11/02/2021                Doubtnut                Edu Tech   \n",
       "9   22/02/2021                  Zomato             Hospitality   \n",
       "10  19/02/2021               Fingerlix             Hospitality   \n",
       "11  17/02/2021                   Zolve                 FinTech   \n",
       "12  15/02/2021               KreditBee                 Finance   \n",
       "13  12/02/2021               Pepperfry              E-commerce   \n",
       "14  12/02/2021                 Grofers              E-Commerce   \n",
       "15  09/02/2021                 Nothing              Technology   \n",
       "16  09/02/2021             SplashLearn                  EdTech   \n",
       "17  04/03/2021               DealShare              E-commerce   \n",
       "18  31/03/2021                Uniphore              Technology   \n",
       "19  30/03/2021                   Dunzo              E-commerce   \n",
       "20  30/03/2021                  BYJU’S                Edu-tech   \n",
       "21  23/03/2021             SkilloVilla                Edu-tech   \n",
       "22  25/03/2021                CityMall              E-commerce   \n",
       "23  26/03/2021                   DotPe                 FinTech   \n",
       "\n",
       "                                         Sub-Vertical           Location  \\\n",
       "0                                  Insurance Services          Bengaluru   \n",
       "1       Shave care, beard care, and skincare products          New Delhi   \n",
       "2   online marketplace for farm products and services              Patna   \n",
       "3                                             HR Tech             Mumbai   \n",
       "4                  AI-powered telemedicine mobile app          Bengaluru   \n",
       "5      Online learning platform for kids in class 1-5            Gurgaon   \n",
       "6                       Whole Food plant based Nashta               Pune   \n",
       "7                                          Pharmacies          Bengaluru   \n",
       "8                                 E-Learning Platform            Gurgaon   \n",
       "9                       Online Food Delivery Platform            Gurgaon   \n",
       "10                      Semi-cooked food delivery app             Mumbai   \n",
       "11                             Global Neobank Venture             Mumbai   \n",
       "12                           Digital lending platform          Bengaluru   \n",
       "13                        Multi-brand furniture brand             Mumbai   \n",
       "14                                 Online supermarket            Gurgaon   \n",
       "15                        Consumer Technology Venture             London   \n",
       "16                      Game-based learning programme            Gurgaon   \n",
       "17                           Online shopping platform  Jaipur, Rajasthan   \n",
       "18            Conversational Service Automation (CSA)          Palo Alto   \n",
       "19                           Hyper-local delivery app          Bengaluru   \n",
       "20                                    Online tutoring          Bengaluru   \n",
       "21                Career and job-oriented upskilling.          Bengaluru   \n",
       "22       Social ecommerce and online grocery platform            Gurgaon   \n",
       "23  Commerce and payments platform to offline ente...            Gurgaon   \n",
       "\n",
       "                                             Investor Investment Type  \\\n",
       "0    A91 Partners, Faering Capital, TVS Capital Funds         Venture   \n",
       "1                                   Reckitt Benckiser         Venture   \n",
       "2                                     Prosus Ventures        Series C   \n",
       "3                                 Salesforce Ventures            Seed   \n",
       "4                          Heritas Capital Management   Venture Round   \n",
       "5                                     Sequoia Capital    Seed Funding   \n",
       "6                               SIDBI Venture Capital          Series   \n",
       "7           Matrix Partners India, RTP Global, others            Seed   \n",
       "8   SIG Global, Sequoia Capital, WaterBridge Ventu...        Series B   \n",
       "9                                  Tiger Global, Kora         Venture   \n",
       "10           Rhodium Trust, Accel Partners and Swiggy        Series C   \n",
       "11     Accel Partners and Lightspeed Venture Partners            Seed   \n",
       "12  Azim Premji’s PremjiInvest and South Korea’s M...        Series C   \n",
       "13                                    InnoVen Capital  Debt Financing   \n",
       "14                         SoftBank Vision Fund (SVF)     Unspecified   \n",
       "15                                                 GV        Series A   \n",
       "16                                       Owl Ventures        Series C   \n",
       "17                                    Innoven Capital  Debt Financing   \n",
       "18                          Sorenson Capital Partners        Series D   \n",
       "19                          Krishtal Advisors Pte Ltd        Series E   \n",
       "20         MC Global Edtech, B Capital, Baron, others        Series F   \n",
       "21                              Titan Capital, others            Seed   \n",
       "22                                     Accel Partners        Series A   \n",
       "23                                               PayU        Series A   \n",
       "\n",
       "   Amount(in USD)  \n",
       "0     1,80,00,000  \n",
       "1    6,172,258.50  \n",
       "2      30,000,000  \n",
       "3      15,000,000  \n",
       "4      16,000,000  \n",
       "5      15,000,000  \n",
       "6     100,000,000  \n",
       "7       4,000,000  \n",
       "8       2,500,000  \n",
       "9     250,000,000  \n",
       "10   2,747,045.20  \n",
       "11    1,50,00,000  \n",
       "12     75,000,000  \n",
       "13      4,773,958  \n",
       "14     55,000,000  \n",
       "15     15,000,000  \n",
       "16     18,000,000  \n",
       "17    250,000,000  \n",
       "18    140,000,000  \n",
       "19      8,000,000  \n",
       "20    460,000,000  \n",
       "21    300,000,000  \n",
       "22     11,000,000  \n",
       "23     27,500,000  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# opening web chrome browser\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "\n",
    "# from trak.in\n",
    "url = \"https://trak.in/\"\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "# do click on funding deals\n",
    "button = driver.find_element_by_xpath('//li[@id=\"menu-item-51510\"]/a').get_attribute('href')\n",
    "driver.get(button)\n",
    "\n",
    "# Empty lists\n",
    "fund_dict = {}\n",
    "fund_dict['Date'] = []\n",
    "fund_dict['Startup Name'] = []\n",
    "fund_dict['Industry/Vertical'] = []\n",
    "fund_dict['Sub-Vertical'] = []\n",
    "fund_dict['Location'] = []\n",
    "fund_dict['Investor'] = []\n",
    "fund_dict['Investment Type'] = []\n",
    "fund_dict['Amount(in USD)'] = []\n",
    "\n",
    "\n",
    "for i in range(54,57):\n",
    "    # Date\n",
    "    dt = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[2]'.format(i))\n",
    "    for d in dt:\n",
    "        fund_dict['Date'].append(d.text)\n",
    "\n",
    "    # Startup Name\n",
    "    sn = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[3]'.format(i))\n",
    "    for n in sn:\n",
    "        fund_dict['Startup Name'].append(n.text)\n",
    "    \n",
    "    # Industry/Vertical\n",
    "    ind = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[4]'.format(i))\n",
    "    for n in ind:\n",
    "        fund_dict['Industry/Vertical'].append(n.text)\n",
    "    \n",
    "    # Sub-Vertical\n",
    "    sv = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[5]'.format(i))\n",
    "    for s in sv:\n",
    "        fund_dict['Sub-Vertical'].append(s.text)\n",
    "\n",
    "    # Location\n",
    "    loc = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[6]'.format(i))\n",
    "    for l in loc:\n",
    "        fund_dict['Location'].append(l.text)\n",
    "    \n",
    "    # Investor\n",
    "    inv = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[7]'.format(i))\n",
    "    for n in inv:\n",
    "        fund_dict['Investor'].append(n.text)\n",
    "    \n",
    "    # Investment Type\n",
    "    invt = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[8]'.format(i))\n",
    "    for n in invt:\n",
    "        fund_dict['Investment Type'].append(n.text)\n",
    "    \n",
    "    # Amount\n",
    "    amt = driver.find_elements_by_xpath('//table[@id=\"tablepress-{}\"]/tbody/tr/td[9]'.format(i))\n",
    "    for a in amt:\n",
    "        fund_dict['Amount(in USD)'].append(a.text)\n",
    "    \n",
    "fund_df = pd.DataFrame(fund_dict)\n",
    "fund_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Write a program to scrap all the available details of best gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "#Q7.webpage\n",
    "url = 'https://www.digit.in/'  \n",
    "driver.get(url)\n",
    "#click search button\n",
    "Lap=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[4]/ul/li[3]/a\")\n",
    "driver.execute_script('arguments[0].click()', Lap)\n",
    "time.sleep(2)\n",
    "\n",
    "G_laptops=driver.find_element_by_xpath(\"/html/body/div[6]/div/div[2]/div[2]/ul/li[10]/a\")\n",
    "driver.execute_script('arguments[0].click()', G_laptops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Empty list\n",
    "name = []\n",
    "Price = []\n",
    "OS = []\n",
    "display = []\n",
    "processor = []\n",
    "HDD = []\n",
    "RAM = []\n",
    "weight = []\n",
    "dimension = []\n",
    "GPU = []\n",
    "\n",
    "time.sleep(1)\n",
    "#scraping names\n",
    "names=driver.find_elements_by_xpath(\"//div[@class='right-container']/div/a/h3\")\n",
    "for i in names:\n",
    "    name.append(i.text)\n",
    "\n",
    "time.sleep(1)\n",
    "#scraping operating system\n",
    "os=driver.find_elements_by_xpath(\"//div[@class='product-detail']/div/ul/li[1]/div/div\")\n",
    "for i in os:\n",
    "    OS.append(i.text)\n",
    "\n",
    "time.sleep(1)\n",
    "#scraping display\n",
    "displays=driver.find_elements_by_xpath(\"//div[@class='product-detail']/div/ul/li[2]/div/div\")\n",
    "for i in displays:\n",
    "    display.append(i.text)\n",
    "\n",
    "\n",
    "time.sleep(1)\n",
    "# scraping memory\n",
    "memories=driver.find_elements_by_xpath(\"//div[@class='Spcs-details'][1]/table/tbody/tr[6]/td[3]\")# extrat HDD and RAM form xpath\n",
    "for i in memories:\n",
    "    HDD.append(i.text.split(\"/\")[0])\n",
    "    \n",
    "    RAM.append(i.text.split(\"/\")[1])\n",
    "\n",
    "time.sleep(1)\n",
    "# scraping weight\n",
    "weights=driver.find_elements_by_xpath(\"//div[@class='Spcs-details'][1]/table/tbody/tr[7]/td[3]\")# extrat weight form xpath\n",
    "for i in weights:\n",
    "    weight.append(i.text)\n",
    "\n",
    "time.sleep(1)\n",
    "# scraping dimension\n",
    "dimension=[]\n",
    "dimensions=driver.find_elements_by_xpath(\"//div[@class='Spcs-details'][1]/table/tbody/tr[8]/td[3]\") \n",
    "for i in dimensions:\n",
    "    dimension.append(i.text)\n",
    "\n",
    "time.sleep(1)\n",
    "# scraping graphical processor\n",
    "GPUs=driver.find_elements_by_xpath(\"//div[@class='Spcs-details'][1]/table/tbody/tr[9]/td[3]\") \n",
    "for i in GPUs:\n",
    "    GPU.append(i.text)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "#scraping price\n",
    "price=driver.find_elements_by_xpath(\"//table[@id='summtable']//tr//td[3]\")\n",
    "for i in price:\n",
    "    Price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>price</th>\n",
       "      <th>OS</th>\n",
       "      <th>Display</th>\n",
       "      <th>HDD</th>\n",
       "      <th>RAM</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Graphical processor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSI RAIDER GE76</td>\n",
       "      <td>₹ 429,940</td>\n",
       "      <td>WINDOWS 11 HOME</td>\n",
       "      <td>17\" (3840 X 2160)</td>\n",
       "      <td>2 TB SSD</td>\n",
       "      <td>16 GBGB DDR5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>397 x 284 x 26</td>\n",
       "      <td>NVIDIA GeForce RTX 3080Ti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS ROG STRIX SCAR 15</td>\n",
       "      <td>₹ 285,390</td>\n",
       "      <td>WINDOWS 11 HOME</td>\n",
       "      <td>15.6\" (2560 X 1440)</td>\n",
       "      <td>2 TB SSD</td>\n",
       "      <td>32 GBGB DDR5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>259 x 354 x 27</td>\n",
       "      <td>NVIDIA GeForce RTX 3070 Ti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACER NITRO 5</td>\n",
       "      <td>₹ 129,990</td>\n",
       "      <td>WINDOWS 10</td>\n",
       "      <td>15.6\" (1920 X 1080)</td>\n",
       "      <td>1 TB HDD</td>\n",
       "      <td>16 GBGB DDR4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>363.4 x 255 x 23.9</td>\n",
       "      <td>NVIDIA GeForce RTX 3070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSI STEALTH 15M</td>\n",
       "      <td>₹ 134,990</td>\n",
       "      <td>WINDOWS 10</td>\n",
       "      <td>15.6\" (1920 X 1080)</td>\n",
       "      <td>1 TB SSD</td>\n",
       "      <td>16 GBGB DDR4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>358.3 x 248 x 16.15</td>\n",
       "      <td>NVIDIA GeForce RTX 3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS ROG STRIX SCAR 15</td>\n",
       "      <td>₹ 193,990</td>\n",
       "      <td>WINDOWS 10</td>\n",
       "      <td>15.6\" (2560 X 1440)</td>\n",
       "      <td>2 TB SSD</td>\n",
       "      <td>32 GBGB DDR4</td>\n",
       "      <td>2.30</td>\n",
       "      <td>354 x 259 x 22.6</td>\n",
       "      <td>NVIDIA GeForce RTX 3080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS ROG STRIX SCAR 15</td>\n",
       "      <td>₹ 215,990</td>\n",
       "      <td>WINDOWS 10 HOME</td>\n",
       "      <td>15.6\" (1920 X 1080)</td>\n",
       "      <td>1 TB SSD</td>\n",
       "      <td>16 GBGB DDR4</td>\n",
       "      <td>2.30</td>\n",
       "      <td>35.4 x 25.9 x 2.26</td>\n",
       "      <td>NVIDIA® GeForce RTX™ 3070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS ZEPHYRUS G14</td>\n",
       "      <td>₹ 144,990</td>\n",
       "      <td>WINDOWS 10 HOME</td>\n",
       "      <td>14\" (1920 X 1080)</td>\n",
       "      <td>1 TB SSD</td>\n",
       "      <td>16 GBGB DDR4</td>\n",
       "      <td>1.65</td>\n",
       "      <td>32.5 x 22.1 x 1.8</td>\n",
       "      <td>NVIDIA GeForce RTX 2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP OMEN 16</td>\n",
       "      <td>₹ 139,990</td>\n",
       "      <td>WINDOWS 11 HOME</td>\n",
       "      <td>16.1\" (1920 X 1080)</td>\n",
       "      <td>1 TB SSD</td>\n",
       "      <td>16 GBGB DDR4</td>\n",
       "      <td>2.32</td>\n",
       "      <td>36.92 x 24.8 x 2.3</td>\n",
       "      <td>NVIDIA GeForce RTX 3060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS ROG ZEPHYRUS DUO 15</td>\n",
       "      <td>₹ 185,000</td>\n",
       "      <td>WINDOWS 10</td>\n",
       "      <td>15.6\" (3840 X 1100)</td>\n",
       "      <td>512 GB SSD</td>\n",
       "      <td>4 GBGB DDR4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>268.30 x 360.00 x 20.90</td>\n",
       "      <td>NVIDIA GeForce RTX 2070 Max-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ACER ASPIRE 7 GAMING LAPTOP</td>\n",
       "      <td>₹ 53,490</td>\n",
       "      <td>WINDOWS 10 HOME</td>\n",
       "      <td>15.6\" (1920 X 1080)</td>\n",
       "      <td>512 GB SSD</td>\n",
       "      <td>8 GBGB DDR4</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.29 x 36.3 x 25.4</td>\n",
       "      <td>NVIDIA® GeForce® GTX 1650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name      price               OS  \\\n",
       "0              MSI RAIDER GE76  ₹ 429,940  WINDOWS 11 HOME   \n",
       "1       ASUS ROG STRIX SCAR 15  ₹ 285,390  WINDOWS 11 HOME   \n",
       "2                 ACER NITRO 5  ₹ 129,990       WINDOWS 10   \n",
       "3              MSI STEALTH 15M  ₹ 134,990       WINDOWS 10   \n",
       "4       ASUS ROG STRIX SCAR 15  ₹ 193,990       WINDOWS 10   \n",
       "5       ASUS ROG STRIX SCAR 15  ₹ 215,990  WINDOWS 10 HOME   \n",
       "6            ASUS ZEPHYRUS G14  ₹ 144,990  WINDOWS 10 HOME   \n",
       "7                   HP OMEN 16  ₹ 139,990  WINDOWS 11 HOME   \n",
       "8     ASUS ROG ZEPHYRUS DUO 15  ₹ 185,000       WINDOWS 10   \n",
       "9  ACER ASPIRE 7 GAMING LAPTOP   ₹ 53,490  WINDOWS 10 HOME   \n",
       "\n",
       "               Display         HDD           RAM Weight  \\\n",
       "0    17\" (3840 X 2160)    2 TB SSD  16 GBGB DDR5    2.9   \n",
       "1  15.6\" (2560 X 1440)    2 TB SSD  32 GBGB DDR5    2.3   \n",
       "2  15.6\" (1920 X 1080)    1 TB HDD  16 GBGB DDR4    2.4   \n",
       "3  15.6\" (1920 X 1080)    1 TB SSD  16 GBGB DDR4    1.7   \n",
       "4  15.6\" (2560 X 1440)    2 TB SSD  32 GBGB DDR4   2.30   \n",
       "5  15.6\" (1920 X 1080)    1 TB SSD  16 GBGB DDR4   2.30   \n",
       "6    14\" (1920 X 1080)    1 TB SSD  16 GBGB DDR4   1.65   \n",
       "7  16.1\" (1920 X 1080)    1 TB SSD  16 GBGB DDR4   2.32   \n",
       "8  15.6\" (3840 X 1100)  512 GB SSD   4 GBGB DDR4    2.4   \n",
       "9  15.6\" (1920 X 1080)  512 GB SSD   8 GBGB DDR4   2.15   \n",
       "\n",
       "                 Dimension            Graphical processor  \n",
       "0           397 x 284 x 26      NVIDIA GeForce RTX 3080Ti  \n",
       "1           259 x 354 x 27     NVIDIA GeForce RTX 3070 Ti  \n",
       "2       363.4 x 255 x 23.9        NVIDIA GeForce RTX 3070  \n",
       "3      358.3 x 248 x 16.15        NVIDIA GeForce RTX 3060  \n",
       "4         354 x 259 x 22.6        NVIDIA GeForce RTX 3080  \n",
       "5       35.4 x 25.9 x 2.26      NVIDIA® GeForce RTX™ 3070  \n",
       "6        32.5 x 22.1 x 1.8        NVIDIA GeForce RTX 2060  \n",
       "7       36.92 x 24.8 x 2.3        NVIDIA GeForce RTX 3060  \n",
       "8  268.30 x 360.00 x 20.90  NVIDIA GeForce RTX 2070 Max-Q  \n",
       "9       2.29 x 36.3 x 25.4      NVIDIA® GeForce® GTX 1650  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make data frame\n",
    "df=pd.DataFrame({\"Name\":name,\n",
    "                \"price\":Price,\n",
    "                \"OS\":OS,\n",
    "                \"Display\":display,\n",
    "                \"HDD\":HDD,\n",
    "                \"RAM\":RAM,\n",
    "                \"Weight\":weight,\n",
    "                \"Dimension\":dimension,\n",
    "                \"Graphical processor\":GPU})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "#Q8.webpage\n",
    "url = 'https://www.forbes.com/?sh=69e6b8c92254'  \n",
    "driver.get(url)\n",
    "\n",
    "#click search button\n",
    "search_btn = driver.find_element_by_xpath(\"//button[@class='icon--hamburger']\")\n",
    "search_btn.click()\n",
    "\n",
    "#click search button\n",
    "search_btn = driver.find_element_by_xpath(\"//div[@class='header__channels--wrapper']\")\n",
    "search_btn.click()\n",
    "\n",
    "#select billionaire  \n",
    "\n",
    "billioners = driver.find_element_by_xpath(\"/html/body/div[1]/header/nav/div[3]/ul/li[1]\")\n",
    "\n",
    "billioners.click()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "#select world billionaire  \n",
    "\n",
    "world_billioners= driver.find_element_by_xpath(\"/html/body/div[1]/header/nav/div[3]/ul/li[1]/div[2]/ul/li[2]/a\")\n",
    "\n",
    "world_billioners.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>NetWorth</th>\n",
       "      <th>Age</th>\n",
       "      <th>Citizenship</th>\n",
       "      <th>Source</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>$219 B</td>\n",
       "      <td>50</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tesla, SpaceX</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>$171 B</td>\n",
       "      <td>58</td>\n",
       "      <td>United States</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>$158 B</td>\n",
       "      <td>73</td>\n",
       "      <td>France</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>$129 B</td>\n",
       "      <td>66</td>\n",
       "      <td>United States</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Warren Buffett</td>\n",
       "      <td>$118 B</td>\n",
       "      <td>91</td>\n",
       "      <td>United States</td>\n",
       "      <td>Berkshire Hathaway</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank                      Name NetWorth Age    Citizenship  \\\n",
       "0    1                 Elon Musk   $219 B  50  United States   \n",
       "1    2                Jeff Bezos   $171 B  58  United States   \n",
       "2    3  Bernard Arnault & family   $158 B  73         France   \n",
       "3    4                Bill Gates   $129 B  66  United States   \n",
       "4    5            Warren Buffett   $118 B  91  United States   \n",
       "\n",
       "               Source               Industry  \n",
       "0       Tesla, SpaceX             Automotive  \n",
       "1              Amazon             Technology  \n",
       "2                LVMH       Fashion & Retail  \n",
       "3           Microsoft             Technology  \n",
       "4  Berkshire Hathaway  Finance & Investments  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank = []\n",
    "name = []\n",
    "networth = []\n",
    "age = []\n",
    "citizenship = []\n",
    "source = [] \n",
    "industry = []\n",
    "\n",
    "for i in range(0,15):\n",
    "    nm = driver.find_elements_by_xpath('//div[@class=\"personName\"]')\n",
    "    rnk = driver.find_elements_by_xpath('//div[@class=\"rank\"]')\n",
    "    worth = driver.find_elements_by_xpath('//div[@class=\"netWorth\"]')\n",
    "    ag = driver.find_elements_by_xpath('//div[@class=\"age\"]')\n",
    "    citi = driver.find_elements_by_xpath('//div[@class=\"countryOfCitizenship\"]')\n",
    "    sour = driver.find_elements_by_xpath('//div[@class=\"source-column\"]')\n",
    "    indus = driver.find_elements_by_xpath('//div[@class=\"category\"]')\n",
    "    \n",
    "    for i in rnk:\n",
    "        rank.append(i.text.replace('.',''))\n",
    "    for j in nm:\n",
    "        name.append(j.text)\n",
    "    \n",
    "    for k in worth:\n",
    "        networth.append(k.text)\n",
    "        \n",
    "    for l in ag:\n",
    "        age.append(l.text)\n",
    "        \n",
    "    for m in citi:\n",
    "        citizenship.append(m.text)\n",
    "        \n",
    "    for n in sour:\n",
    "        source.append(n.text)\n",
    "    \n",
    "    for o in indus:\n",
    "        industry.append(o.text)\n",
    "        \n",
    "    \n",
    "        \n",
    "    try:\n",
    "        nxt = driver.find_element_by_xpath('//button[@class=\"pagination-btn pagination-btn--next \"]')\n",
    "        nxt.click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "\n",
    "    \n",
    "billionaires = pd.DataFrame({})\n",
    "billionaires['Rank'] = rank\n",
    "billionaires['Name'] = name\n",
    "billionaires['NetWorth'] = networth\n",
    "billionaires['Age'] = age\n",
    "billionaires['Citizenship']  = citizenship\n",
    "billionaires['Source'] =  source\n",
    "billionaires['Industry'] = industry\n",
    "billionaires.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted from any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get(\"https://www.youtube.com/watch?v=TFr6G5zveS8\")\n",
    "\n",
    "# To scroll down\n",
    "for _ in range(1000):\n",
    "    driver.execute_script('window.scrollBy(0,5000)')\n",
    "    \n",
    "comment = []\n",
    "vote = []\n",
    "time = []\n",
    "\n",
    "# Scrapping Comment\n",
    "try:\n",
    "    comment_tag = driver.find_elements_by_id('content-text')\n",
    "    for i in comment_tag:\n",
    "        comment.append(i.text)\n",
    "except NoSuchElementException:\n",
    "        comment.append(\"-\")    \n",
    "\n",
    "# Scrapping upvote\n",
    "try:\n",
    "    vote_tag = driver.find_elements_by_id(\"vote-count-middle\")\n",
    "    for j in vote_tag:\n",
    "        vote.append(j.text)\n",
    "except NoSuchElementException:\n",
    "        vote.append(\"-\")\n",
    "\n",
    "#Scrapping time\n",
    "try:   \n",
    "    time_tag = driver.find_elements_by_xpath(\"//a[@class='yt-simple-endpoint style-scope yt-formatted-string']\")\n",
    "    for k in time_tag:\n",
    "        time.append(k.text)\n",
    "except NoSuchElementException:\n",
    "        time.append(\"-\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Upvote</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RIP Lata Mangeshkar Ji ❤ Thank you for giving ...</td>\n",
       "      <td>7.5K</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A message to the future generation.\"don't Let ...</td>\n",
       "      <td>35</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just imagine this song was recorded 58 years b...</td>\n",
       "      <td>88</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is April 2022. This  continues to be a popu...</td>\n",
       "      <td>100</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's still hard to believe that the magician o...</td>\n",
       "      <td>179</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Love this ❤ song in may 15 , sunday</td>\n",
       "      <td></td>\n",
       "      <td>2 months ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>May 2022, let's see how many people are listen...</td>\n",
       "      <td></td>\n",
       "      <td>3 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>You are the best singer lata didi but i miss y...</td>\n",
       "      <td></td>\n",
       "      <td>1 month ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Not sure what's more divine, Lataji's voice, M...</td>\n",
       "      <td>210</td>\n",
       "      <td>1 month ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>All time favorite song. Amazing song. Lataji a...</td>\n",
       "      <td></td>\n",
       "      <td>6 months ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comments Upvote          Time\n",
       "0    RIP Lata Mangeshkar Ji ❤ Thank you for giving ...   7.5K              \n",
       "1    A message to the future generation.\"don't Let ...     35              \n",
       "2    Just imagine this song was recorded 58 years b...     88              \n",
       "3    It is April 2022. This  continues to be a popu...    100              \n",
       "4    It's still hard to believe that the magician o...    179              \n",
       "..                                                 ...    ...           ...\n",
       "495                Love this ❤ song in may 15 , sunday         2 months ago\n",
       "496  May 2022, let's see how many people are listen...          3 weeks ago\n",
       "497  You are the best singer lata didi but i miss y...          1 month ago\n",
       "498  Not sure what's more divine, Lataji's voice, M...    210   1 month ago\n",
       "499  All time favorite song. Amazing song. Lataji a...         6 months ago\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DataFrame\n",
    "df = pd.DataFrame({'Comments':comment[0:500], 'Upvote':vote[0:500], 'Time':time[17:517]})\n",
    "df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in “London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews,overall reviews, privates from price, dorms from price, facilities and property description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.get(\"https://www.hostelworld.com/s?q=London, England&country=England&city=London&type=city&id=3&from=2022-05-25&to=2022-05-28&guests=2&page=1\")\n",
    "\n",
    "title = []\n",
    "distance = []\n",
    "rating = []\n",
    "total_review = []\n",
    "prices = []\n",
    "private_price = []\n",
    "dorms_price = []\n",
    "facilities=[]\n",
    "prop_details=[]\n",
    "\n",
    "title_tags = driver.find_elements_by_xpath(\"//h2[@class='title title-6']\")\n",
    "for i in title_tags:\n",
    "    title.append(i.text)\n",
    "    \n",
    "distance_tags = driver.find_elements_by_xpath(\"//span[@class='description']\")\n",
    "for j in distance_tags:\n",
    "    distance.append(j.text.split('-')[1])\n",
    "\n",
    "rating_tags = driver.find_elements_by_xpath(\"//div[@class='score orange big']\")\n",
    "for k in rating_tags:\n",
    "    rating.append(k.text)\n",
    "\n",
    "total_review_tags = driver.find_elements_by_xpath(\"//div[@class='reviews']\")\n",
    "for l in total_review_tags:\n",
    "    total_review.append(l.text)\n",
    "\n",
    "    \n",
    "P_prices_tags=driver.find_elements_by_xpath(\"//div[1][@class='price-col']\") #locating web element of price\n",
    "    \n",
    "for n in P_prices_tags:\n",
    "    private_price.append(n.text)\n",
    "\n",
    "\n",
    "D_prices_tags=driver.find_elements_by_xpath(\"//div[2][@class='price-col']\") #locating web element of price\n",
    "  \n",
    "for o in D_prices_tags:\n",
    "    dorms_price.append(o.text)\n",
    "\n",
    "faci_tags=driver.find_elements_by_xpath(\"//div[@class='facilities-label facilities']\")    \n",
    "for p in faci_tags:\n",
    "    facilities.append(p.text)\n",
    "\n",
    "prop_des=driver.find_elements_by_xpath(\"//div[@class='title-row']\")    \n",
    "for q in prop_des:\n",
    "    prop_details.append(q.text)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hostel Name</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Total Review</th>\n",
       "      <th>Private Price</th>\n",
       "      <th>Dorms Price</th>\n",
       "      <th>Property Details</th>\n",
       "      <th>Facilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Palmers Lodge - Swiss Cottage</td>\n",
       "      <td>6.5km from city centre</td>\n",
       "      <td>8.9</td>\n",
       "      <td>15339 Total Reviews</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Dorms From\\nRs3715</td>\n",
       "      <td>Palmers Lodge - Swiss Cottage\\nHostel - 6.5km ...</td>\n",
       "      <td>Free WiFi\\nFollows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generator London</td>\n",
       "      <td>3km from city centre</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6939 Total Reviews</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Dorms From\\nRs2746</td>\n",
       "      <td>Palmers Lodge - Swiss Cottage\\nHostel - 6.5km ...</td>\n",
       "      <td>Free WiFi\\nFollows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Urbany Hostel London</td>\n",
       "      <td>5.4km from city centre</td>\n",
       "      <td>9.4</td>\n",
       "      <td>306 Total Reviews</td>\n",
       "      <td>Privates From\\nRs17092</td>\n",
       "      <td>No Dorms Available</td>\n",
       "      <td>Generator London\\nHostel - 3km from city centr...</td>\n",
       "      <td>Free WiFi\\nFollows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Safestay London Elephant &amp; Castle</td>\n",
       "      <td>1.7km from city centre</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4240 Total Reviews</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Dorms From\\nRs2837</td>\n",
       "      <td>Urbany Hostel London\\nHostel - 5.4km from city...</td>\n",
       "      <td>Free WiFi\\nFollows Covid-19 sanitation guidance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Safestay London Kensington Holland Park</td>\n",
       "      <td>5.9km from city centre</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1191 Total Reviews</td>\n",
       "      <td>No Privates Available</td>\n",
       "      <td>Dorms From\\nRs2398</td>\n",
       "      <td>Safestay London Elephant &amp; Castle\\nHostel - 1....</td>\n",
       "      <td>Free WiFi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Hostel Name                 Distance Rating  \\\n",
       "0            Palmers Lodge - Swiss Cottage   6.5km from city centre    8.9   \n",
       "1                         Generator London     3km from city centre    7.6   \n",
       "2                     Urbany Hostel London   5.4km from city centre    9.4   \n",
       "3        Safestay London Elephant & Castle   1.7km from city centre    7.2   \n",
       "4  Safestay London Kensington Holland Park   5.9km from city centre    6.7   \n",
       "\n",
       "          Total Review           Private Price         Dorms Price  \\\n",
       "0  15339 Total Reviews   No Privates Available  Dorms From\\nRs3715   \n",
       "1   6939 Total Reviews   No Privates Available  Dorms From\\nRs2746   \n",
       "2    306 Total Reviews  Privates From\\nRs17092  No Dorms Available   \n",
       "3   4240 Total Reviews   No Privates Available  Dorms From\\nRs2837   \n",
       "4   1191 Total Reviews   No Privates Available  Dorms From\\nRs2398   \n",
       "\n",
       "                                    Property Details  \\\n",
       "0  Palmers Lodge - Swiss Cottage\\nHostel - 6.5km ...   \n",
       "1  Palmers Lodge - Swiss Cottage\\nHostel - 6.5km ...   \n",
       "2  Generator London\\nHostel - 3km from city centr...   \n",
       "3  Urbany Hostel London\\nHostel - 5.4km from city...   \n",
       "4  Safestay London Elephant & Castle\\nHostel - 1....   \n",
       "\n",
       "                                        Facilities  \n",
       "0  Free WiFi\\nFollows Covid-19 sanitation guidance  \n",
       "1  Free WiFi\\nFollows Covid-19 sanitation guidance  \n",
       "2  Free WiFi\\nFollows Covid-19 sanitation guidance  \n",
       "3  Free WiFi\\nFollows Covid-19 sanitation guidance  \n",
       "4                                        Free WiFi  "
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Hostel Name':title[:5],'Distance':distance[:5],'Rating':rating[:5],'Total Review':total_review[:5],'Private Price':private_price[:5], 'Dorms Price':dorms_price[:5],'Property Details':prop_details[:5],'Facilities':facilities[:5]})\n",
    "df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.digit.in/laptops/asus-tuf-gaming-laptop-fx506li-hn270t-price-256693.html']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scraping all product url\n",
    "url_laptop = [i.get_attribute(\"href\") for i in driver.find_elements_by_xpath(\"/html/body/div[6]/div[2]/div[2]/div[3]/a\")]\n",
    "url_laptop \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASUS', 'TUF', 'Gaming', 'Laptop', 'FX506LI-HN270T']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name=[]\n",
    "for j in driver.find_elements_by_xpath(\"//div[@class= 'searchProduct-desc']\"):\n",
    "    Name.append(j.text)\n",
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'click'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [157]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m search\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m      7\u001b[0m searchbar\u001b[38;5;241m=\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_element_by_id(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobalPageSearchText\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m search_btn\u001b[38;5;241m=\u001b[39m\u001b[43msearchbar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgaming laptop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m()\n\u001b[0;32m     10\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     12\u001b[0m Name\u001b[38;5;241m=\u001b[39m[]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'click'"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=\"https://www.digit.in/\"\n",
    "driver.get(url)\n",
    "\n",
    "search=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[2]/a/img\")\n",
    "search.click()\n",
    "searchbar=driver.find_element_by_id(\"globalPageSearchText\")\n",
    "search_btn=searchbar.send_keys(\"gaming laptop\").click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "Name=[]\n",
    "for j in driver.find_elements_by_xpath(\"//div[@class= 'searchProduct-desc']\"):\n",
    "    Name.append(j.text)\n",
    "Name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
